# threshold_PGG
The behavioral task used in this project was a modified version of the binary threshold public goods game (PGG), implemented entirely in PsychoPy to allow full control over stimulus presentation, timing, and integration of social feedback mechanisms.
PsychoPy Task Description (≈350 words)

The behavioral task used in this study was a fully customized implementation of a binary threshold public goods game (PGG), developed from the ground up in PsychoPy to enable precise manipulation of both accuracy-dependent and accuracy-independent external outcomes. Although the conceptual structure was inspired by earlier MATLAB/Psychtoolbox versions used in PGG research, the present study required a redesigned task architecture, new feedback mechanisms, and dynamic agent behavior. For this reason, the entire task was rebuilt in PsychoPy to ensure full experimental control and compatibility with Python-based simulations.

Each trial began with the participant receiving a single token. The participant then had up to five seconds to choose whether to contribute the token to the public pool or withhold it. Group success depended on whether total contributions reached the required threshold (k=2 or k=4), allowing systematic comparison across different uncertainty levels. Monetary payoffs were tied to this outcome, creating accuracy-dependent external rewards because the participant’s payoff depended on whether their belief about group participation was correct.

To emulate realistic group dynamics, the decisions of four artificial agents were simulated using a logistic model parameterized to reflect variability observed in human behavior. The model incorporated the participant’s previous action, the previous round’s success or failure, and random perturbations in sensitivity, producing diverse patterns of cooperation and defection. These calculations were executed using Python code embedded within PsychoPy’s Builder and Code components, ensuring real-time generation of agent decisions on each trial.

In half of the blocks, an additional manipulation was introduced: accuracy-independent external outcomes in the form of explicit social feedback. After each round, participants received evaluative social cues indicating whether their decision was socially desirable, neutral, or misaligned with group expectations. These cues were independent of the correctness of the participant’s belief and therefore allowed direct testing of how non-accuracy-based feedback influences belief updating and cooperative behavior.

Across trials, the task recorded participants’ choices, trial-by-trial beliefs about expected group contributions, reaction times, and affective self-reports. These measures enabled the extraction of multiple behavioral indicators relevant to belief updating. Together, the design provides a controlled, scalable environment for examining how different classes of external outcomes jointly shape the value assigned to beliefs and the decisions that follow.

# How to run?
To use this task, the entire project folder must be extracted before running the experiment. After unzipping the directory, the task can be launched by opening the file ThresholdPGG.psyexp in PsychoPy. It is important to note that this task was originally written for Persian-speaking participants; therefore, all instructions, labels, and on-screen messages are in Persian. Anyone intending to use the task in a different linguistic context will need to translate the instruction pages, decision prompts, feedback screens, and any textual elements within the .psyexp file before running the experiment with non-Persian speakers.
